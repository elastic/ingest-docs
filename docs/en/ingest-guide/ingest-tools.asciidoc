[[ingest-tools]]
== Tools for ingesting time-series data 


Elastic and others offer tools to help you get your data from the original data source into {es}.
Some tools are designed for particular data sources, and others are multi-purpose. 

// Iterative messaging as our recommended strategy morphs. 
// This section is the summary. "Here's the story _now_." 
// Hint at upcoming changes, but do it cautiously and responsibly. 
// Modular and co-located to make additions/updates/deprecations easier as our story matures.


In this section, we'll help you determine which option is best for you.

* <<ingest-ea>>
* <<ingest-beats>>
* <<ingest-otel>>
* <<ingest-logstash>>

[discrete]
[[ingest-ea]]
=== {agent} and Elastic integrations

A single link:{fleet-guide}[{agent}] can collect multiple types of data when it is link:{fleet-guide}/elastic-agent-installation.html[installed] on a host computer.  
You can use standalone {agent}s and manage them locally on the systems where they are installed, or you can manage all of your agents and policies with the link:{fleet-guide}/manage-agents-in-fleet.html[Fleet UI in {kib}].

Use {agent} with one of hundreds of link:{integrations-docs}[Elastic integrations] to simplify collecting, transforming, and visualizing data. 
Integrations include default ingestion rules, dashboards, and visualizations to help you start analyzing your data right away. 
Check out the {integrations-docs}/all_integrations[Integration quick reference] to search for available integrations that can reduce your time to value.  

{agent} is the best option for collecting timestamped data for most data sources
and use cases. 
If your data requires additional processing before going to {es}, you can use
link:{fleet-guide}/elastic-agent-processor-configuration.html[{agent}
processors], link:{logstash-ref}[{ls}], or additional processing features in
{es}. 
Check out <<ingest-addl-proc,additional processing>> to see options. 

Ready to try link:{fleet-guide}[{agent}]? Check out the link:{fleet-guide}/elastic-agent-installation.html[installation instructions].

[discrete]
[[ingest-beats]]
=== {beats}

link:{beats-ref}/beats-reference.html[Beats] are the original Elastic lightweight data shippers, and their capabilities live on in Elastic Agent.
When you use Elastic Agent, you're getting core Beats functionality, but with more added features. 


Beats require that you install a separate Beat for each type of data you want to collect. 
A single Elastic Agent installed on a host can collect and transport multiple types of data.  

**Best practice:** Use link:{fleet-guide}[{agent}] whenever possible. 
If your data source is not yet supported by {agent}, use {beats}. 
Check out the {beats} and {agent} link:{fleet-guide}/beats-agent-comparison.html#additional-capabilities-beats-and-agent[comparison] for more info.
When you are ready to upgrade, check out link:{fleet-guide}/migrate-beats-to-agent.html[Migrate from {beats} to {agent}].

[discrete]
[[ingest-otel]]
=== OpenTelemetry (OTel) collectors

link:https://opentelemetry.io/docs[OpenTelemetry] is a vendor-neutral observability framework for collecting, processing, and exporting telemetry data.
Elastic is a member of the Cloud Native Computing Foundation (CNCF) and active contributor to the OpenTelemetry project. 

In addition to supporting upstream OTel development, Elastic provides link:https://github.com/elastic/opentelemetry[Elastic Distributions of OpenTelemetry], specifically designed to work with Elastic Observability.
We're also expanding link:{fleet-guide}[{agent}] to use OTel collection. 

[discrete]
[[ingest-logstash]]
=== Logstash

link:{logstash-ref}[{ls}] is a versatile open source data ETL (extract, transform, load) engine that can expand your ingest capabilities.
{ls} can _collect data_ from a wide variety of data sources with {ls} link:{logstash-ref}/input-plugins.html[input
plugins], _enrich and transform_ the data with {ls} link:{logstash-ref}/filter-plugins.html[filter plugins], and _output_ the
data to {es} and other destinations with the {ls} link:{logstash-ref}/output-plugins.html[output plugins].

Many users never need to use {ls}, but it's available if you need it for: 

* **Data collection** (if an Elastic integration isn't available). 
{agent} and Elastic {integrations-docs}/all_integrations[integrations] provide many features out-of-the-box, so be sure to search or browse integrations for your data source. 
If you don't find an Elastic integration for your data source, check {ls} for an {logstash-ref}/input-plugins.html[input plugin] for your data source. 
* **Additional processing.** One of the most common {ls} use cases is link:{logstash-ref}/ea-integrations.html[extending Elastic integrations].
You can take advantage of the extensive, built-in capabilities of Elastic Agent and Elastic Integrations, and
then use {ls} for additional data processing before sending the data on to {es}. 
* **Advanced use cases.** {ls} can help with advanced use cases, such as when you need
link:{ingest-guide}/lspq.html[persistence or buffering],
additional link:{ingest-guide}/ls-enrich.html[data enrichment],  
link:{ingest-guide}/ls-networkbridge.html[proxying] as a way to bridge network connections, or the ability to route data to
link:{ingest-guide}/ls-multi.html[multiple destinations].
