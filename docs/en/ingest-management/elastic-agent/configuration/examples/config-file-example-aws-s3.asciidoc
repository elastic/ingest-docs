[[config-file-example-aws-s3]]
= Config file example: AWS S3

++++
<titleabbrev>AWS S3</titleabbrev>
++++

Include these sample settings in your standalone {agent} `elastic-agent.yml` configuration file to ingest data from from AWS S3.

* <<config-file-example-aws-s3-logs>>
* <<config-file-example-aws-s3-metrics>>

[discrete]
[[config-file-example-aws-s3-logs]]
== AWS S3 access logs

["source","yaml"]
----
outputs: <1>
  default:
    type: elasticsearch <2>
    hosts:
      - '{elasticsearch-host-url}' <3>
    api_key: "my_api_key" <4>
agent:
  download: <5>
    sourceURI: 'https://artifacts.elastic.co/downloads/'
  monitoring: <6>
    enabled: true
    use_output: default
    namespace: default
    logs: true
    metrics: true
inputs: <7>
  - id: "insert a unique identifier here" <8>
    name: aws-1
    revision: 1
    type: aws-s3 <9>
    use_output: default
    data_stream: <10>
      namespace: default
    streams:
      - id: "insert a unique identifier here" <11>
        data_stream: <10>
          dataset: aws.s3access <12>
          type: logs <9>
        queue_url: 'http://queue.url'
        max_number_of_messages: 5
        tags:
          - forwarded
          - aws-s3access
        publisher_pipeline.disable_host: true
----

<1> For available output settings, refer to <<elastic-agent-output-configuration,Configure outputs for standalone {agents}>>.
<2> For settings specific to the {es} output, refer to <<elasticsearch-output,Configure the {es} output>>.
<3> The URL of the {es} cluster where output should be sent, including the port number. For example `https://12345ab6789cd12345ab6789cd.us-central1.gcp.cloud.es.io:443`.
<4> An <<create-api-key-standalone-agent,API key>> used to authenticate with the {es} cluster.
<5> For available download settings, refer to <<elastic-agent-standalone-download,Configure download settings for standalone Elastic Agent upgrades>>.
<6> For available monitoring settings, refer to <<elastic-agent-monitoring-configuration,Configure monitoring for standalone {agents}>>.
<7> For available input settings, refer to <<elastic-agent-input-configuration,Configure inputs for standalone {agents}>>.
<8> A user-defined ID to uniquely identify the input stream.
<9> For available input types, refer to <<elastic-agent-inputs-list>>.
<10> Learn about <<data-streams>> for time series data.
<11> Specify a unique ID for each individual input stream. Naming the ID by appending the associated `data_stream` dataset (for example `{user-defined-unique-id}-aws.s3access`) is a recommended practice, but any unique ID will work.
<12> Refer to the {integrations-docs}/aws#reference[reference section] in the AWS integration documentation for the type of metrics collected and exported fields.

[discrete]
[[config-file-example-aws-s3-metrics]]
== AWS S3 daily storage and request metrics

["source","yaml"]
----
outputs: <1>
  default:
    type: elasticsearch <2>
    hosts:
      - '{elasticsearch-host-url}' <3>
    api_key: "my_api_key" <4>
agent:
  download: <5>
    sourceURI: 'https://artifacts.elastic.co/downloads/'
  monitoring: <6>
    enabled: true
    use_output: default
    namespace: default
    logs: true
    metrics: true
inputs: <7>
  - id: "insert a unique identifier here" <8>
    name: aws-2
    revision: 1
    type: aws/metrics <9>
    use_output: default
    data_stream: <10>
      namespace: default
    streams:
      - id: "insert a unique identifier here" <11>
        data_stream: <10>
          dataset: aws.s3_daily_storage <12>
          type: metrics
        metricsets: <13>
          - cloudwatch
        period: 24h
        metrics:
          - name:
              - BucketSizeBytes
              - NumberOfObjects
            namespace: AWS/S3
            statistic:
              - Average
      - id: "insert a unique identifier here" <8>
        data_stream: <10>
          dataset: aws.s3_request <12>
          type: metrics
        metricsets: <13>
          - cloudwatch
        period: 1m
        metrics:
          - name:
              - SelectScannedBytes
              - SelectReturnedBytes
              - BytesDownloaded
              - BytesUploaded
              - 4xxErrors
              - 5xxErrors
              - FirstByteLatency
              - TotalRequestLatency
            namespace: AWS/S3
            statistic:
              - Average
          - name:
              - AllRequests
              - GetRequests
              - PutRequests
              - DeleteRequests
              - HeadRequests
              - PostRequests
              - SelectRequests
              - ListRequests
              - BytesDownloaded
              - BytesUploaded
            namespace: AWS/S3
            statistic:
              - Sum
----

<1> For available output settings, refer to <<elastic-agent-output-configuration,Configure outputs for standalone {agents}>>.
<2> For settings specific to the {es} output, refer to <<elasticsearch-output,Configure the {es} output>>.
<3> The URL of the Elasticsearch cluster where output should be sent, including the port number. For example `https://12345ab6789cd12345ab6789cd.us-central1.gcp.cloud.es.io:443`.
<4> An <<create-api-key-standalone-agent,API key>> used to authenticate with the {es} cluster.
<5> For available download settings, refer to <<elastic-agent-standalone-download,Configure download settings for standalone Elastic Agent upgrades>>.
<6> For available monitoring settings, refer to <<elastic-agent-monitoring-configuration,Configure monitoring for standalone {agents}>>.
<7> For available input settings, refer to <<elastic-agent-input-configuration,Configure inputs for standalone {agents}>>.
<8> A user-defined ID to uniquely identify the input stream.
<9> For available input types, refer to <<elastic-agent-inputs-list>>.
<10> Learn about <<data-streams>> for time series data.
<11> Specify a unique ID for each individual input stream. Naming the ID by appending the associated `data_stream` dataset (for example `{user-defined-unique-id}-aws.cloudwatch`) is a recommended practice, but any unique ID will work.
<12> A user-defined dataset. You can specify anything that makes sense to signify the source of the data.
<13> Refer to the {integrations-docs}/aws#reference[reference section] in the AWS integration documentation for the type of metrics collected and exported fields.