:type: output-elasticsearch

[[elasticsearch-output]]
= Configure the {es} output

++++
<titleabbrev>{es}</titleabbrev>
++++

The {es} output sends events directly to {es} by using the {es} HTTP API.

*Compatibility:* This output works with all compatible versions of {es}. See the
https://www.elastic.co/support/matrix#matrix_compatibility[Elastic Support
Matrix].

This example configures an {es} output called `default` in the
`elastic-agent.yml` file:

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: [127.0.0.1:9200]
    username: elastic
    password: changeme
----

This example is similar to the previous one, except that it uses the recommended
<<output-elasticsearch-apikey-authentication-settings,token-based (API key) authentication>>:

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: [127.0.0.1:9200]
    api_key: "my_api_key"
----

NOTE: Token-based authentication is required in an
link:{serverless-docs}[{serverless-full}] environment.

== {es} output configuration settings

The `elasticsearch` output type supports the following settings, grouped by
category. Many of these settings have sensible defaults that allow you to run
{agent} with minimal configuration.

* <<output-elasticsearch-commonly-used-settings>>

* <<output-elasticsearch-authentication-settings>>

* <<output-elasticsearch-data-parsing-settings>>

* <<output-elasticsearch-http-settings>>

* <<output-elasticsearch-memory-queue-settings>>

* <<output-elasticsearch-performance-tuning-settings>>

[[output-elasticsearch-commonly-used-settings]]
== Commonly used settings

[cols="2*<a"]
|===
| Setting | Description

// =============================================================================

include::output-shared-settings.asciidoc[tag=enabled-setting]

*Default:* `true`

// =============================================================================

// tag::hosts-setting[]
|
[id="{type}-hosts-setting"]
`hosts`

| (list) The list of {es} nodes to connect to. The events are distributed to
these nodes in round robin order. If one node becomes unreachable, the event is
automatically sent to another node. Each {es} node can be defined as a `URL` or
`IP:PORT`. For example: `http://192.15.3.2`, `https://es.found.io:9230` or
`192.24.3.2:9300`. If no port is specified, `9200` is used.

NOTE: When a node is defined as an `IP:PORT`, the _scheme_ and _path_ are taken
from the `protocol` and `path` settings. 

[source,yaml]
------------------------------------------------------------------------------
outputs:
  default:
    type: elasticsearch
    hosts: ["10.45.3.2:9220", "10.45.3.1:9230"] <1>
    protocol: https
    path: /elasticsearch
------------------------------------------------------------------------------
<1> In this example, the {es} nodes are available at
`https://10.45.3.2:9220/elasticsearch` and
`https://10.45.3.1:9230/elasticsearch`.
// end::hosts-setting[]

// =============================================================================

// tag::protocol-setting[]
|
[id="{type}-protocol-setting"]
`protocol`

| (string) The name of the protocol {es} is reachable on. The options are:
`http` or `https`. The default is `http`. However, if you specify a URL for
`hosts`, the value of `protocol` is overridden by whatever scheme you specify in
the URL.
// end::protocol-setting[]

// =============================================================================

// tag::proxy_disable-setting[]
|
[id="{type}-proxy_disable-setting"]
`proxy_disable`

| (boolean) If set to `true`, all proxy settings, including `HTTP_PROXY` and
`HTTPS_PROXY` variables, are ignored.

*Default:* `false`

// end::proxy_disable-setting[]

// =============================================================================

// tag::proxy_headers-setting[]
|
[id="{type}-proxy_headers-setting"]
`proxy_headers`

| (string) Additional headers to send to proxies during CONNECT requests.

// end::proxy_headers-setting[]

// =============================================================================
// tag::proxy_url-setting[]
|
[id="{type}-proxy_url-setting"]
`proxy_url`

| (string) The URL of the proxy to use when connecting to the {es} servers. The
value may be either a complete URL or a `host[:port]`, in which case the `http`
scheme is assumed. If a value is not specified through the configuration file
then proxy environment variables are used. See the
https://golang.org/pkg/net/http/#ProxyFromEnvironment[Go documentation]
for more information about the environment variables.
// end::proxy_url-setting[]

// =============================================================================

|===

[[output-elasticsearch-authentication-settings]]
== Authentication settings

When sending data to a secured cluster through the `elasticsearch`
output, {agent} can use any of the following authentication methods:

* <<output-elasticsearch-basic-authentication-settings>>
* <<output-elasticsearch-apikey-authentication-settings>>
* <<output-elasticsearch-pki-certs-authentication-settings>>
* <<output-elasticsearch-kerberos-authentication-settings>>

[[output-elasticsearch-basic-authentication-settings]]
=== Basic authentication credentials

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: ["https://myEShost:9200"]
    username: "your-username"
    password: "your-password"
----

[cols="2*<a"]
|===
| Setting | Description

// tag::password-setting[]
|
[id="{type}-password-setting"]
`password`

| (string) The basic authentication password for connecting to {es}.
// end::password-setting[]

// =============================================================================

// tag::username-setting[]
|
[id="{type}-username-setting"]
`username`

| (string) The basic authentication username for connecting to {es}.

This user needs the privileges required to publish events to {es}.
//To create a user like this, refer to <<privileges-to-publish-events>>.
// end::username-setting[]

Note that in an link:{serverless-docs}[{serverless-full}] environment you need to use <<output-elasticsearch-apikey-authentication-settings,token-based (API key) authentication>>.

// =============================================================================

|===

[[output-elasticsearch-apikey-authentication-settings]]
=== Token-based (API key) authentication

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: ["https://myEShost:9200"]
    api_key: "KnR6yE41RrSowb0kQ0HWoA"
----

[cols="2*<a"]
|===
| Setting | Description

// tag::api_key-setting[]
|
[id="{type}-api_key-setting"]
`api_key`

| (string) Instead of using a username and password, you can use {kibana-ref}/api-keys.html[API keys] to
secure communication with {es}. The value must be the ID of the API key and the
API key joined by a colon: `id:api_key`. Token-based authentication is required in an link:{serverless-docs}[{serverless-full}] environment.
// end::api_key-setting[]

// =============================================================================

|===

[[output-elasticsearch-pki-certs-authentication-settings]]
=== Public Key Infrastructure (PKI) certificates

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: ["https://myEShost:9200"]
    ssl.certificate: "/etc/pki/client/cert.pem"
    ssl.key: "/etc/pki/client/cert.key"
----

For a list of available settings, refer to <<elastic-agent-ssl-configuration>>,
specifically the settings under <<common-ssl-options>> and
<<client-ssl-options>>.

[[output-elasticsearch-kerberos-authentication-settings]]
=== Kerberos

The following encryption types are supported:

// lint ignore
* aes128-cts-hmac-sha1-96
* aes128-cts-hmac-sha256-128
* aes256-cts-hmac-sha1-96
* aes256-cts-hmac-sha384-192
* des3-cbc-sha1-kd
* rc4-hmac

Example output config with Kerberos password-based authentication:

[source,yaml]
----
outputs:
  default:
    type: elasticsearch
    hosts: ["http://my-elasticsearch.elastic.co:9200"]
    kerberos.auth_type: password
    kerberos.username: "elastic"
    kerberos.password: "changeme"
    kerberos.config_path: "/etc/krb5.conf"
    kerberos.realm: "ELASTIC.CO"
----

The service principal name for the {es} instance is constructed from these
options. Based on this configuration, the name would be:

`HTTP/my-elasticsearch.elastic.co@ELASTIC.CO`

include::../authentication/kerberos-shared-settings.asciidoc[tag=kerberos-all-settings]

[[output-elasticsearch-data-parsing-settings]]
=== Data parsing, filtering, and manipulation settings

Settings used to parse, filter, and transform data.

[cols="2*<a"]
|===
| Setting | Description

include::output-shared-settings.asciidoc[tag=escape_html-setting]

// =============================================================================

// tag::pipeline-setting[]
|
[id="{type}-pipeline-setting"]
`pipeline`

| (string) A format string value that specifies the
{ref}/ingest.html[ingest pipeline] to write events to.

[source,yaml]
------------------------------------------------------------------------------
outputs:
  default:
    type: elasticsearchoutput.elasticsearch:
    hosts: ["http://localhost:9200"]
    pipeline: my_pipeline_id
------------------------------------------------------------------------------

You can set the ingest pipeline dynamically by using a format string to
access any event field. For example, this configuration uses a custom field,
`fields.log_type`, to set the pipeline for each event:

[source,yaml]
------------------------------------------------------------------------------
outputs:
  default:
    type: elasticsearch  hosts: ["http://localhost:9200"]
    pipeline: "%{[fields.log_type]}_pipeline"
------------------------------------------------------------------------------

With this configuration, all events with `log_type: normal` are sent to a
pipeline named `normal_pipeline`, and all events with `log_type: critical` are
sent to a pipeline named `critical_pipeline`.

TIP: To learn how to add custom fields to events, see the `fields` option.

See the `pipelines` setting for other ways to set the ingest pipeline
dynamically.
// end::pipelines-setting[]

// =============================================================================

// tag::pipelines-setting[]
|
[id="{type}-pipelines-setting"]
`pipelines`

| An array of pipeline selector rules. Each rule specifies the {ref}/ingest.html[ingest pipeline]
to use for events that match the rule. During publishing, {agent} uses the first
matching rule in the array. Rules can contain conditionals, format string-based
fields, and name mappings. If the `pipelines` setting is missing or no rule
matches, the `pipeline` setting is used.

Rule settings:

*`pipeline`*:: The pipeline format string to use. If this string contains field
references, such as `%{[fields.name]}`, the fields must exist, or the rule
fails.

*`mappings`*:: A dictionary that takes the value returned by `pipeline` and maps
it to a new name.

*`default`*:: The default string value to use if `mappings` does not find a
match.

*`when`*:: A condition that must succeed in order to execute the current rule.

All the conditions supported by processors are also supported here.

The following example sends events to a specific pipeline based on whether the
`message` field contains the specified string:

[source,yaml]
------------------------------------------------------------------------------
outputs:
  default:
    type: elasticsearch  hosts: ["http://localhost:9200"]
    pipelines:
      - pipeline: "warning_pipeline"
        when.contains:
          message: "WARN"
      - pipeline: "error_pipeline"
        when.contains:
          message: "ERR"
------------------------------------------------------------------------------


The following example sets the pipeline by taking the name returned by the
`pipeline` format string and mapping it to a new name that's used for the
pipeline:

[source,yaml]
------------------------------------------------------------------------------
outputs:
  default:
    type: elasticsearch
    hosts: ["http://localhost:9200"]
    pipelines:
      - pipeline: "%{[fields.log_type]}"
        mappings:
          critical: "sev1_pipeline"
          normal: "sev2_pipeline"
        default: "sev3_pipeline"
------------------------------------------------------------------------------


With this configuration, all events with `log_type: critical` are sent to
`sev1_pipeline`, all events with `log_type: normal` are sent to a
`sev2_pipeline`, and all other events are sent to `sev3_pipeline`.

// end::pipelines-setting[]

// =============================================================================

|===

[[output-elasticsearch-http-settings]]
== HTTP settings

Settings that modify the HTTP requests sent to {es}.

[cols="2*<a"]
|===
| Setting | Description


// tag::headers-setting[]
|
[id="{type}-headers-setting"]
`headers`

| Custom HTTP headers to add to each request created by the {es} output.

Example:

[source,yaml]
------------------------------------------------------------------------------
outputs:
  default:
    type: elasticsearch
    headers:
      X-My-Header: Header contents
------------------------------------------------------------------------------

Specify multiple header values for the same header name by separating them with
a comma.
// end::headers-setting[]

// =============================================================================

// tag::parameters-setting[]
|
[id="{type}-parameters-setting"]
`parameters`

| Dictionary of HTTP parameters to pass within the URL with index operations.
// end::parameters-setting[]

// =============================================================================

// tag::path-setting[]
|
[id="{type}-path-setting"]
`path`

| (string) An HTTP path prefix that is prepended to the HTTP API calls. This is
useful for the cases where {es} listens behind an HTTP reverse proxy that
exports the API under a custom prefix.
// end::path-setting[]

// =============================================================================

|===

[[output-elasticsearch-memory-queue-settings]]
== Memory queue settings

The memory queue keeps all events in memory.

The memory queue waits for the output to acknowledge or drop events. If
the queue is full, no new events can be inserted into the memory queue. Only
after the signal from the output will the queue free up space for more events to be accepted.

The memory queue is controlled by the parameters `queue.mem.flush.min_events` and `queue.mem.flush.timeout`. If
`queue.mem.flush.timeout` is `0s` or `queue.mem.flush.min_events` is `0` or `1` then events can be sent by the output as
soon as they are available. If the output supports a `bulk_max_size` parameter it controls the
maximum batch size that can be sent.

If `queue.mem.flush.min_events` is greater than `1` and `queue.mem.flush.timeout` is greater than `0s`, events will only
be sent to the output when the queue contains at least `queue.mem.flush.min_events` events or the
`queue.mem.flush.timeout` period has expired. In this mode the maximum size batch that that can be sent by the
output is `queue.mem.flush.min_events`. If the output supports a `bulk_max_size` parameter, values of
`bulk_max_size` greater than `queue.mem.flush.min_events` have no effect. The value of `queue.mem.flush.min_events`
should be evenly divisible by `bulk_max_size` to avoid sending partial batches to the output.

This sample configuration forwards events to the output if 512 events are available or the oldest
available event has been waiting for 5s in the queue:

[source,yaml]
------------------------------------------------------------------------------
  queue.mem.events: 4096
  queue.mem.flush.min_events: 512
  queue.mem.flush.timeout: 5s
------------------------------------------------------------------------------

[cols="2*<a"]
|===
| Setting | Description

include::output-shared-settings.asciidoc[tag=queue.mem.events-setting]

// =============================================================================

include::output-shared-settings.asciidoc[tag=queue.mem.flush.min_events-setting]

// =============================================================================

include::output-shared-settings.asciidoc[tag=queue.mem.flush.timeout-setting]

// =============================================================================

|===

[[output-elasticsearch-performance-tuning-settings]]
== Performance tuning settings

Settings that may affect performance when sending data through the {es} output.

Use the `preset` option to automatically configure the group of performance tuning settings to optimize for `throughput`, `scale`, `latency`, or you can select a `balanced` set of performance specifications. 

The performance tuning `preset` values take precedence over any settings that may be defined separately. If you want to change any setting, set `preset` to `custom` and specify the performance tuning settings individually.

[cols="2*<a"]
|===
| Setting | Description

// tag::backoff.init-setting[]
|
[id="{type}-backoff.init-setting"]
`backoff.init`

| (string) The number of seconds to wait before trying to reconnect to {es}
after a network error. After waiting `backoff.init` seconds, {agent} tries to
reconnect. If the attempt fails, the backoff timer is increased exponentially up
to `backoff.max`. After a successful connection, the backoff timer is reset.

*Default:* `1s`
// end::backoff.init-setting[]

// =============================================================================

// tag::backoff.max-setting[]
|
[id="{type}-backoff.max-setting"]
`backoff.max`

| (string) The maximum number of seconds to wait before attempting to connect to
{es} after a network error.

*Default:* `60s`
// end::backoff.max-setting[]

// =============================================================================

// tag::bulk_max_size-setting[]
|
[id="{type}-bulk_max_size-setting"]
`bulk_max_size`

| (int) The maximum number of events to bulk in a single {es} bulk API index
request. 

Events can be collected into batches. {agent} will split batches larger than
`bulk_max_size` into multiple batches.

Specifying a larger batch size can improve performance by lowering the overhead
of sending events. However big batch sizes can also increase processing times,
which might result in API errors, killed connections, timed-out publishing
requests, and, ultimately, lower throughput.

Setting `bulk_max_size` to values less than or equal to 0 turns off the
splitting of batches. When splitting is disabled, the queue decides on the
number of events to be contained in a batch.

*Default:* `1600`
// end::bulk_max_size-setting[]

// =============================================================================

include::output-shared-settings.asciidoc[tag=compression_level-setting]

*Default:* `1`

// =============================================================================

// tag::max_retries-setting[]
|
[id="{type}-max_retries-setting"]
`max_retries`

| (int) The number of times to retry publishing an event after a publishing
failure. After the specified number of retries, the events are typically
dropped.

Set `max_retries` to a value less than 0 to retry until all events are published.

*Default:* `3`
// end::max_retries-setting[]

// =============================================================================

// tag::preset-setting[]
|
[id="{type}-preset-setting"]
`preset`

| Configures the full group of <<output-elasticsearch-performance-tuning-settings,performance tuning settings>> to optimize your {agent} performance when sending data to an {es} output.

Refer to <<es-output-settings-performance-tuning-settings>> for a table showing the group of values associated with any preset, and another table showing EPS (events per second) results from testing the different preset options.

Performance tuning preset settings:

*`balanced`*::
Configure the default tuning setting values for "out-of-the-box" performance.

*`throughput`*::
Optimize the {es} output for throughput.

*`scale`*::
Optimize the {es} output for scale.

*`latency`*::
Optimize the {es} output to reduce latence.

*`custom`*::
Use the `custom` option to fine-tune the performance tuning settings individually.

*Default:* `balanced`
// end::preset-setting[]

// =============================================================================

// tag::timeout-setting[]
|
[id="{type}-timeout-setting"]
`timeout`

| (string) The HTTP request timeout in seconds for the {es} request.

*Default:* `90s`

// end::timeout-setting[]

// =============================================================================

include::output-shared-settings.asciidoc[tag=worker-setting]

// =============================================================================

|===

:type!: 
